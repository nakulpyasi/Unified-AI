{
  
    
        "post0": {
            "title": "Title",
            "content": "# Same as numpy # The main diff is pytorch works on a gpu import numpy as np import torch import pandas as pd . inp = np.arange(58,387,step = 5.5, dtype=np.float32).reshape(10,6) inp.dtype . dtype(&#39;float32&#39;) . actual = np.arange(6000,9000,step = 320.7,dtype=np.float32) actual.dtype actual.shape . (10,) . inp= torch.from_numpy(inp) actual = torch.from_numpy(actual) . # requires grad will make sure that gradients will be automatically calculated for the tensor # Define the datatypes to match the input and output tesnsor wt = torch.randn(6, requires_grad=True) bias = torch.randn(1, requires_grad=True) . wt.dtype,bias.dtype . (torch.float32, torch.float32) . def model(inp): return inp @ wt.t() + bias . pred = model(inp) pred, &#39;+&#39;*100 , inp . (tensor([12.7866, 13.0640, 13.3413, 13.6186, 13.8960, 14.1733, 14.4507, 14.7280, 15.0053, 15.2827], grad_fn=&lt;AddBackward0&gt;), &#39;++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++&#39;, tensor([[ 58.0000, 63.5000, 69.0000, 74.5000, 80.0000, 85.5000], [ 91.0000, 96.5000, 102.0000, 107.5000, 113.0000, 118.5000], [124.0000, 129.5000, 135.0000, 140.5000, 146.0000, 151.5000], [157.0000, 162.5000, 168.0000, 173.5000, 179.0000, 184.5000], [190.0000, 195.5000, 201.0000, 206.5000, 212.0000, 217.5000], [223.0000, 228.5000, 234.0000, 239.5000, 245.0000, 250.5000], [256.0000, 261.5000, 267.0000, 272.5000, 278.0000, 283.5000], [289.0000, 294.5000, 300.0000, 305.5000, 311.0000, 316.5000], [322.0000, 327.5000, 333.0000, 338.5000, 344.0000, 349.5000], [355.0000, 360.5000, 366.0000, 371.5000, 377.0000, 382.5000]])) . def mse(t1, t2): diff = t1 - t2 return torch.sum(diff * diff) / diff.numel() # calculation of loss considering random wts and bias is initialized loss = mse(pred,actual) loss . tensor(56038804., grad_fn=&lt;DivBackward0&gt;) . loss.backward() . print(wt) print(wt.grad) print(bias.grad) . tensor([-0.8699, 0.5496, -0.3244, 0.2490, 0.4581, -0.0539], requires_grad=True) tensor([-3242695.5000, -3324415.5000, -3406136.0000, -3487856.2500, -3569576.5000, -3651296.7500]) tensor([-14858.2334]) . # -ve gradient - decrease wt - more loss # +ve gradient - increase wt - more loss # +ve gradient - decrease wt - less loss # Increase and decrease of loss is proportional to the gradient of the loss # torch.no_grad that the gradient is not calculated while updating the wt&#39;s and the bias # 1e-5 is the learning rate to make sure we move slowly towards the minimum of cost function with torch.no_grad(): wt -= wt.grad * 1e-5 bias -= bias.grad * 1e-5 . tensor(56038804., grad_fn=&lt;DivBackward0&gt;) . wt.grad.zero_() bias.grad.zero_() . tensor([0.]) . preds = model(inp) print(preds) loss = mse(preds, actual) print(loss) . tensor([14930.9082, 21756.2363, 28581.5684, 35406.8984, 42232.2305, 49057.5586, 55882.8867, 62708.2148, 69533.5469, 76358.8672], grad_fn=&lt;AddBackward0&gt;) tensor(1.8084e+09, grad_fn=&lt;DivBackward0&gt;) . with torch.no_grad(): wt -= wt.grad * 1e-5 bias -= bias.grad * 1e-5 wt.grad.zero_() bias.grad.zero_() . print(wt) print(bias) . tensor([31.5571, 33.7937, 33.7370, 35.1276, 36.1538, 36.4590], requires_grad=True) tensor([0.2911], requires_grad=True) . preds = model(inp) loss = mse(preds, actual) print(loss) . tensor(1.8084e+09, grad_fn=&lt;DivBackward0&gt;) . for i in range(100): preds = model(inp) loss = mse(preds, actual) loss.backward() with torch.no_grad(): wt -= wt.grad * 1e-8 bias -= bias.grad * 1e-8 wt.grad.zero_() bias.grad.zero_() print(loss) . tensor(1.1706e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.1551e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.1398e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.1247e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.1098e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.0951e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.0806e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.0663e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.0523e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.0384e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.0247e+08, grad_fn=&lt;DivBackward0&gt;) tensor(1.0112e+08, grad_fn=&lt;DivBackward0&gt;) tensor(99783600., grad_fn=&lt;DivBackward0&gt;) tensor(98469440., grad_fn=&lt;DivBackward0&gt;) tensor(97173368., grad_fn=&lt;DivBackward0&gt;) tensor(95895144., grad_fn=&lt;DivBackward0&gt;) tensor(94634504., grad_fn=&lt;DivBackward0&gt;) tensor(93391240., grad_fn=&lt;DivBackward0&gt;) tensor(92165096., grad_fn=&lt;DivBackward0&gt;) tensor(90955816., grad_fn=&lt;DivBackward0&gt;) tensor(89763208., grad_fn=&lt;DivBackward0&gt;) tensor(88587008., grad_fn=&lt;DivBackward0&gt;) tensor(87426992., grad_fn=&lt;DivBackward0&gt;) tensor(86282960., grad_fn=&lt;DivBackward0&gt;) tensor(85154672., grad_fn=&lt;DivBackward0&gt;) tensor(84041944., grad_fn=&lt;DivBackward0&gt;) tensor(82944512., grad_fn=&lt;DivBackward0&gt;) tensor(81862200., grad_fn=&lt;DivBackward0&gt;) tensor(80794792., grad_fn=&lt;DivBackward0&gt;) tensor(79742064., grad_fn=&lt;DivBackward0&gt;) tensor(78703856., grad_fn=&lt;DivBackward0&gt;) tensor(77679928., grad_fn=&lt;DivBackward0&gt;) tensor(76670096., grad_fn=&lt;DivBackward0&gt;) tensor(75674192., grad_fn=&lt;DivBackward0&gt;) tensor(74691976., grad_fn=&lt;DivBackward0&gt;) tensor(73723280., grad_fn=&lt;DivBackward0&gt;) tensor(72767904., grad_fn=&lt;DivBackward0&gt;) tensor(71825728., grad_fn=&lt;DivBackward0&gt;) tensor(70896488., grad_fn=&lt;DivBackward0&gt;) tensor(69980080., grad_fn=&lt;DivBackward0&gt;) tensor(69076256., grad_fn=&lt;DivBackward0&gt;) tensor(68184896., grad_fn=&lt;DivBackward0&gt;) tensor(67305792., grad_fn=&lt;DivBackward0&gt;) tensor(66438804., grad_fn=&lt;DivBackward0&gt;) tensor(65583744., grad_fn=&lt;DivBackward0&gt;) tensor(64740472., grad_fn=&lt;DivBackward0&gt;) tensor(63908812., grad_fn=&lt;DivBackward0&gt;) tensor(63088596., grad_fn=&lt;DivBackward0&gt;) tensor(62279680., grad_fn=&lt;DivBackward0&gt;) tensor(61481900., grad_fn=&lt;DivBackward0&gt;) tensor(60695092., grad_fn=&lt;DivBackward0&gt;) tensor(59919096., grad_fn=&lt;DivBackward0&gt;) tensor(59153812., grad_fn=&lt;DivBackward0&gt;) tensor(58399072., grad_fn=&lt;DivBackward0&gt;) tensor(57654720., grad_fn=&lt;DivBackward0&gt;) tensor(56920600., grad_fn=&lt;DivBackward0&gt;) tensor(56196588., grad_fn=&lt;DivBackward0&gt;) tensor(55482560., grad_fn=&lt;DivBackward0&gt;) tensor(54778368., grad_fn=&lt;DivBackward0&gt;) tensor(54083864., grad_fn=&lt;DivBackward0&gt;) tensor(53398920., grad_fn=&lt;DivBackward0&gt;) tensor(52723412., grad_fn=&lt;DivBackward0&gt;) tensor(52057192., grad_fn=&lt;DivBackward0&gt;) tensor(51400168., grad_fn=&lt;DivBackward0&gt;) tensor(50752156., grad_fn=&lt;DivBackward0&gt;) tensor(50113088., grad_fn=&lt;DivBackward0&gt;) tensor(49482808., grad_fn=&lt;DivBackward0&gt;) tensor(48861220., grad_fn=&lt;DivBackward0&gt;) tensor(48248176., grad_fn=&lt;DivBackward0&gt;) tensor(47643592., grad_fn=&lt;DivBackward0&gt;) tensor(47047312., grad_fn=&lt;DivBackward0&gt;) tensor(46459252., grad_fn=&lt;DivBackward0&gt;) tensor(45879276., grad_fn=&lt;DivBackward0&gt;) tensor(45307292., grad_fn=&lt;DivBackward0&gt;) tensor(44743192., grad_fn=&lt;DivBackward0&gt;) tensor(44186856., grad_fn=&lt;DivBackward0&gt;) tensor(43638184., grad_fn=&lt;DivBackward0&gt;) tensor(43097064., grad_fn=&lt;DivBackward0&gt;) tensor(42563388., grad_fn=&lt;DivBackward0&gt;) tensor(42037064., grad_fn=&lt;DivBackward0&gt;) tensor(41517988., grad_fn=&lt;DivBackward0&gt;) tensor(41006060., grad_fn=&lt;DivBackward0&gt;) tensor(40501188., grad_fn=&lt;DivBackward0&gt;) tensor(40003256., grad_fn=&lt;DivBackward0&gt;) tensor(39512176., grad_fn=&lt;DivBackward0&gt;) tensor(39027864., grad_fn=&lt;DivBackward0&gt;) tensor(38550220., grad_fn=&lt;DivBackward0&gt;) tensor(38079148., grad_fn=&lt;DivBackward0&gt;) tensor(37614560., grad_fn=&lt;DivBackward0&gt;) tensor(37156376., grad_fn=&lt;DivBackward0&gt;) tensor(36704496., grad_fn=&lt;DivBackward0&gt;) tensor(36258836., grad_fn=&lt;DivBackward0&gt;) tensor(35819320., grad_fn=&lt;DivBackward0&gt;) tensor(35385848., grad_fn=&lt;DivBackward0&gt;) tensor(34958348., grad_fn=&lt;DivBackward0&gt;) tensor(34536732., grad_fn=&lt;DivBackward0&gt;) tensor(34120928., grad_fn=&lt;DivBackward0&gt;) tensor(33710836., grad_fn=&lt;DivBackward0&gt;) tensor(33306410., grad_fn=&lt;DivBackward0&gt;) tensor(32907540., grad_fn=&lt;DivBackward0&gt;) . preds = model(inp) loss = mse(preds, actual) print(loss) . tensor(32514160., grad_fn=&lt;DivBackward0&gt;) . preds . tensor([ 3773.3501, 5489.8921, 7206.4336, 8922.9756, 10639.5166, 12356.0586, 14072.6006, 15789.1426, 17505.6836, 19222.2246], grad_fn=&lt;AddBackward0&gt;) . actual . tensor([6000.0000, 6320.7002, 6641.4004, 6962.1006, 7282.8008, 7603.5010, 7924.2012, 8244.9014, 8565.6016, 8886.3018]) .",
            "url": "https://nakulpyasi.github.io/Unified-AI/2022/08/14/nn_from_scratch_pytorch.html",
            "relUrl": "/2022/08/14/nn_from_scratch_pytorch.html",
            "date": " • Aug 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Gradient Descent from Scratch using",
            "content": "About . This notebook is an implementation of a gradient descent using PYTORCH . gradient_descent is the foundation of all deep learning problems. It is super critical tp understand this . import numpy as np import torch import pandas as pd from torch.utils.data import TensorDataset from torch.utils.data import DataLoader from torch.utils.data import random_split import torch.nn as nnß import torch.nn.functional as F . inp = np.arange(58,387,step = 5.5, dtype=np.float32).reshape(10,6) inp.dtype, inp.shape inp . array([[ 58. , 63.5, 69. , 74.5, 80. , 85.5], [ 91. , 96.5, 102. , 107.5, 113. , 118.5], [124. , 129.5, 135. , 140.5, 146. , 151.5], [157. , 162.5, 168. , 173.5, 179. , 184.5], [190. , 195.5, 201. , 206.5, 212. , 217.5], [223. , 228.5, 234. , 239.5, 245. , 250.5], [256. , 261.5, 267. , 272.5, 278. , 283.5], [289. , 294.5, 300. , 305.5, 311. , 316.5], [322. , 327.5, 333. , 338.5, 344. , 349.5], [355. , 360.5, 366. , 371.5, 377. , 382.5]], dtype=float32) . actual = np.arange(6000,9000,step = 320.7,dtype=np.float32).reshape(10,1) actual.dtype, actual.shape actual . array([[6000. ], [6320.7 ], [6641.4004], [6962.1006], [7282.801 ], [7603.501 ], [7924.201 ], [8244.901 ], [8565.602 ], [8886.302 ]], dtype=float32) . inp= torch.from_numpy(inp) actual = torch.from_numpy(actual) . ds = TensorDataset(inp, actual) # To divide the data into train and validation set we use random_split # [8,2] splits the data into training and validation dataset #tr_dataset, val_dataset = random_split(ds,[8,2]) # Dataloader helps to split data into batches and shuffling the data train_loader = DataLoader(ds, shuffle=True) # datatypes of dataset an train_loader type(ds) , type(train_loader) . (torch.utils.data.dataset.TensorDataset, torch.utils.data.dataloader.DataLoader) . #Iteration to see what a dataloader provides for data,label in train_loader: print(data) print(label) . tensor([[157.0000, 162.5000, 168.0000, 173.5000, 179.0000, 184.5000]]) tensor([[6962.1006]]) tensor([[355.0000, 360.5000, 366.0000, 371.5000, 377.0000, 382.5000]]) tensor([[8886.3018]]) tensor([[322.0000, 327.5000, 333.0000, 338.5000, 344.0000, 349.5000]]) tensor([[8565.6016]]) tensor([[190.0000, 195.5000, 201.0000, 206.5000, 212.0000, 217.5000]]) tensor([[7282.8008]]) tensor([[256.0000, 261.5000, 267.0000, 272.5000, 278.0000, 283.5000]]) tensor([[7924.2012]]) tensor([[124.0000, 129.5000, 135.0000, 140.5000, 146.0000, 151.5000]]) tensor([[6641.4004]]) tensor([[289.0000, 294.5000, 300.0000, 305.5000, 311.0000, 316.5000]]) tensor([[8244.9014]]) tensor([[ 91.0000, 96.5000, 102.0000, 107.5000, 113.0000, 118.5000]]) tensor([[6320.7002]]) tensor([[58.0000, 63.5000, 69.0000, 74.5000, 80.0000, 85.5000]]) tensor([[6000.]]) tensor([[223.0000, 228.5000, 234.0000, 239.5000, 245.0000, 250.5000]]) tensor([[7603.5010]]) . . # inputs are the number of columns in a tabular dataset # outputs can be the number of outputs input_size = 6 output_size = 1 model = nn.Linear(input_size,output_size) # To look at the weight and bias use a parameter method list(model.parameters()) # using the model to generate predictions predictions = model(inp) . actual.shape, predictions.shape . (torch.Size([10, 1]), torch.Size([10, 1])) . loss = F.mse_loss(predictions,actual) # Models wts and bias can be updated automatically using a optimizer opt = torch.optim.SGD(model.parameters(),lr = 1e-6) . # Steps for nn implementation num_epochs = 2000 for epoch in range(num_epochs): for data,label in train_loader: # preds preds = model(data) # calculate loss loss = F.mse_loss(preds,label) # gradient calculation loss.backward() # update wts and bias wrt loss opt.step() # gradients values are 0 again opt.zero_grad() if epoch%10==0: print(loss) . tensor(1025286.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(1841393.3750, grad_fn=&lt;MseLossBackward0&gt;) tensor(9880742., grad_fn=&lt;MseLossBackward0&gt;) tensor(15824849., grad_fn=&lt;MseLossBackward0&gt;) tensor(12866921., grad_fn=&lt;MseLossBackward0&gt;) tensor(1403273.8750, grad_fn=&lt;MseLossBackward0&gt;) tensor(6889109., grad_fn=&lt;MseLossBackward0&gt;) tensor(301995.3125, grad_fn=&lt;MseLossBackward0&gt;) tensor(7300813., grad_fn=&lt;MseLossBackward0&gt;) tensor(6569762.5000, grad_fn=&lt;MseLossBackward0&gt;) tensor(8025976., grad_fn=&lt;MseLossBackward0&gt;) tensor(5783595., grad_fn=&lt;MseLossBackward0&gt;) tensor(4533934.5000, grad_fn=&lt;MseLossBackward0&gt;) tensor(1997666.1250, grad_fn=&lt;MseLossBackward0&gt;) tensor(2004032.8750, grad_fn=&lt;MseLossBackward0&gt;) tensor(25588.5957, grad_fn=&lt;MseLossBackward0&gt;) tensor(379602.7812, grad_fn=&lt;MseLossBackward0&gt;) tensor(8045948.5000, grad_fn=&lt;MseLossBackward0&gt;) tensor(3089504.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(5630250.5000, grad_fn=&lt;MseLossBackward0&gt;) tensor(854514.2500, grad_fn=&lt;MseLossBackward0&gt;) tensor(1580122.6250, grad_fn=&lt;MseLossBackward0&gt;) tensor(9193628., grad_fn=&lt;MseLossBackward0&gt;) tensor(128968.6641, grad_fn=&lt;MseLossBackward0&gt;) tensor(1670929.8750, grad_fn=&lt;MseLossBackward0&gt;) tensor(1254736.8750, grad_fn=&lt;MseLossBackward0&gt;) tensor(2535173., grad_fn=&lt;MseLossBackward0&gt;) tensor(528035.6875, grad_fn=&lt;MseLossBackward0&gt;) tensor(4599877., grad_fn=&lt;MseLossBackward0&gt;) tensor(1754838.3750, grad_fn=&lt;MseLossBackward0&gt;) tensor(2620946., grad_fn=&lt;MseLossBackward0&gt;) tensor(1700487.3750, grad_fn=&lt;MseLossBackward0&gt;) tensor(1380360., grad_fn=&lt;MseLossBackward0&gt;) tensor(131735.6875, grad_fn=&lt;MseLossBackward0&gt;) tensor(394955.7812, grad_fn=&lt;MseLossBackward0&gt;) tensor(5332.2085, grad_fn=&lt;MseLossBackward0&gt;) tensor(6262877.5000, grad_fn=&lt;MseLossBackward0&gt;) tensor(576035.0625, grad_fn=&lt;MseLossBackward0&gt;) tensor(3134015., grad_fn=&lt;MseLossBackward0&gt;) tensor(3981889.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(31548.3848, grad_fn=&lt;MseLossBackward0&gt;) tensor(43048.5508, grad_fn=&lt;MseLossBackward0&gt;) tensor(1267220.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(2754742.5000, grad_fn=&lt;MseLossBackward0&gt;) tensor(1623688.1250, grad_fn=&lt;MseLossBackward0&gt;) tensor(799257.8125, grad_fn=&lt;MseLossBackward0&gt;) tensor(2852575.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(1129285., grad_fn=&lt;MseLossBackward0&gt;) tensor(5696063., grad_fn=&lt;MseLossBackward0&gt;) tensor(588753.5000, grad_fn=&lt;MseLossBackward0&gt;) tensor(85174.2031, grad_fn=&lt;MseLossBackward0&gt;) tensor(179881.5938, grad_fn=&lt;MseLossBackward0&gt;) tensor(553601.3750, grad_fn=&lt;MseLossBackward0&gt;) tensor(1017881., grad_fn=&lt;MseLossBackward0&gt;) tensor(336.8515, grad_fn=&lt;MseLossBackward0&gt;) tensor(2092113.6250, grad_fn=&lt;MseLossBackward0&gt;) tensor(1474040.2500, grad_fn=&lt;MseLossBackward0&gt;) tensor(689778.9375, grad_fn=&lt;MseLossBackward0&gt;) tensor(845809.8125, grad_fn=&lt;MseLossBackward0&gt;) tensor(614982.9375, grad_fn=&lt;MseLossBackward0&gt;) tensor(1456556.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(22297.1387, grad_fn=&lt;MseLossBackward0&gt;) tensor(299480.9688, grad_fn=&lt;MseLossBackward0&gt;) tensor(281979.6562, grad_fn=&lt;MseLossBackward0&gt;) tensor(1540737.8750, grad_fn=&lt;MseLossBackward0&gt;) tensor(571171.3750, grad_fn=&lt;MseLossBackward0&gt;) tensor(68729.7422, grad_fn=&lt;MseLossBackward0&gt;) tensor(475251.3438, grad_fn=&lt;MseLossBackward0&gt;) tensor(1260493., grad_fn=&lt;MseLossBackward0&gt;) tensor(1407893.5000, grad_fn=&lt;MseLossBackward0&gt;) tensor(677600.6875, grad_fn=&lt;MseLossBackward0&gt;) tensor(1021236.5625, grad_fn=&lt;MseLossBackward0&gt;) tensor(570050.0625, grad_fn=&lt;MseLossBackward0&gt;) tensor(553846.3125, grad_fn=&lt;MseLossBackward0&gt;) tensor(9212.1562, grad_fn=&lt;MseLossBackward0&gt;) tensor(1395014.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(257966.7812, grad_fn=&lt;MseLossBackward0&gt;) tensor(594758.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(423076.5625, grad_fn=&lt;MseLossBackward0&gt;) tensor(1312152.3750, grad_fn=&lt;MseLossBackward0&gt;) tensor(126852.4922, grad_fn=&lt;MseLossBackward0&gt;) tensor(80669.0391, grad_fn=&lt;MseLossBackward0&gt;) tensor(1004843.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(25011.7012, grad_fn=&lt;MseLossBackward0&gt;) tensor(44540.3711, grad_fn=&lt;MseLossBackward0&gt;) tensor(207787.2969, grad_fn=&lt;MseLossBackward0&gt;) tensor(663612.3125, grad_fn=&lt;MseLossBackward0&gt;) tensor(87480.7734, grad_fn=&lt;MseLossBackward0&gt;) tensor(162032.9844, grad_fn=&lt;MseLossBackward0&gt;) tensor(297660.2812, grad_fn=&lt;MseLossBackward0&gt;) tensor(39607.0234, grad_fn=&lt;MseLossBackward0&gt;) tensor(642594.8125, grad_fn=&lt;MseLossBackward0&gt;) tensor(368919.8125, grad_fn=&lt;MseLossBackward0&gt;) tensor(668199.2500, grad_fn=&lt;MseLossBackward0&gt;) tensor(507437.0938, grad_fn=&lt;MseLossBackward0&gt;) tensor(117289.5234, grad_fn=&lt;MseLossBackward0&gt;) tensor(9352.4385, grad_fn=&lt;MseLossBackward0&gt;) tensor(306672.5938, grad_fn=&lt;MseLossBackward0&gt;) tensor(187027.5312, grad_fn=&lt;MseLossBackward0&gt;) tensor(29711.7949, grad_fn=&lt;MseLossBackward0&gt;) tensor(581607.3125, grad_fn=&lt;MseLossBackward0&gt;) tensor(78159.0156, grad_fn=&lt;MseLossBackward0&gt;) tensor(33897.5195, grad_fn=&lt;MseLossBackward0&gt;) tensor(245715.7812, grad_fn=&lt;MseLossBackward0&gt;) tensor(27524.8828, grad_fn=&lt;MseLossBackward0&gt;) tensor(69760.2109, grad_fn=&lt;MseLossBackward0&gt;) tensor(294287.1875, grad_fn=&lt;MseLossBackward0&gt;) tensor(300696.4062, grad_fn=&lt;MseLossBackward0&gt;) tensor(2979.8379, grad_fn=&lt;MseLossBackward0&gt;) tensor(31175.6953, grad_fn=&lt;MseLossBackward0&gt;) tensor(181176.5938, grad_fn=&lt;MseLossBackward0&gt;) tensor(36089.6094, grad_fn=&lt;MseLossBackward0&gt;) tensor(12538.2041, grad_fn=&lt;MseLossBackward0&gt;) tensor(274085.4688, grad_fn=&lt;MseLossBackward0&gt;) tensor(39457.9023, grad_fn=&lt;MseLossBackward0&gt;) tensor(120143.1328, grad_fn=&lt;MseLossBackward0&gt;) tensor(57.8357, grad_fn=&lt;MseLossBackward0&gt;) tensor(205995.4219, grad_fn=&lt;MseLossBackward0&gt;) tensor(4740.1343, grad_fn=&lt;MseLossBackward0&gt;) tensor(69522.3438, grad_fn=&lt;MseLossBackward0&gt;) tensor(6058.8130, grad_fn=&lt;MseLossBackward0&gt;) tensor(182932.4688, grad_fn=&lt;MseLossBackward0&gt;) tensor(1775.9557, grad_fn=&lt;MseLossBackward0&gt;) tensor(88464.1250, grad_fn=&lt;MseLossBackward0&gt;) tensor(216301.7500, grad_fn=&lt;MseLossBackward0&gt;) tensor(164637.8125, grad_fn=&lt;MseLossBackward0&gt;) tensor(55552.7422, grad_fn=&lt;MseLossBackward0&gt;) tensor(142116.4844, grad_fn=&lt;MseLossBackward0&gt;) tensor(7043.0449, grad_fn=&lt;MseLossBackward0&gt;) tensor(63670.9609, grad_fn=&lt;MseLossBackward0&gt;) tensor(140223.1875, grad_fn=&lt;MseLossBackward0&gt;) tensor(38258.0625, grad_fn=&lt;MseLossBackward0&gt;) tensor(95772.7188, grad_fn=&lt;MseLossBackward0&gt;) tensor(73925.8359, grad_fn=&lt;MseLossBackward0&gt;) tensor(2549.5103, grad_fn=&lt;MseLossBackward0&gt;) tensor(117167.8203, grad_fn=&lt;MseLossBackward0&gt;) tensor(15822.8887, grad_fn=&lt;MseLossBackward0&gt;) tensor(70875.5391, grad_fn=&lt;MseLossBackward0&gt;) tensor(618.2313, grad_fn=&lt;MseLossBackward0&gt;) tensor(108391.4141, grad_fn=&lt;MseLossBackward0&gt;) tensor(5892.9609, grad_fn=&lt;MseLossBackward0&gt;) tensor(25092.8496, grad_fn=&lt;MseLossBackward0&gt;) tensor(18408.9785, grad_fn=&lt;MseLossBackward0&gt;) tensor(110383.8984, grad_fn=&lt;MseLossBackward0&gt;) tensor(3473.5713, grad_fn=&lt;MseLossBackward0&gt;) tensor(45406.4492, grad_fn=&lt;MseLossBackward0&gt;) tensor(68950.8594, grad_fn=&lt;MseLossBackward0&gt;) tensor(16553.3105, grad_fn=&lt;MseLossBackward0&gt;) tensor(103790., grad_fn=&lt;MseLossBackward0&gt;) tensor(1067.5791, grad_fn=&lt;MseLossBackward0&gt;) tensor(22363.9766, grad_fn=&lt;MseLossBackward0&gt;) tensor(82489.8438, grad_fn=&lt;MseLossBackward0&gt;) tensor(12118.9141, grad_fn=&lt;MseLossBackward0&gt;) tensor(10346.6045, grad_fn=&lt;MseLossBackward0&gt;) tensor(1892.2500, grad_fn=&lt;MseLossBackward0&gt;) tensor(6260.9976, grad_fn=&lt;MseLossBackward0&gt;) tensor(76310.8281, grad_fn=&lt;MseLossBackward0&gt;) tensor(24406.4336, grad_fn=&lt;MseLossBackward0&gt;) tensor(41235.1719, grad_fn=&lt;MseLossBackward0&gt;) tensor(50131.3867, grad_fn=&lt;MseLossBackward0&gt;) tensor(13964.5918, grad_fn=&lt;MseLossBackward0&gt;) tensor(20052.9395, grad_fn=&lt;MseLossBackward0&gt;) tensor(12091.7295, grad_fn=&lt;MseLossBackward0&gt;) tensor(44238.5352, grad_fn=&lt;MseLossBackward0&gt;) tensor(8997.7451, grad_fn=&lt;MseLossBackward0&gt;) tensor(16977.7852, grad_fn=&lt;MseLossBackward0&gt;) tensor(36235.7617, grad_fn=&lt;MseLossBackward0&gt;) tensor(39488.7539, grad_fn=&lt;MseLossBackward0&gt;) tensor(3396.1350, grad_fn=&lt;MseLossBackward0&gt;) tensor(6115.8052, grad_fn=&lt;MseLossBackward0&gt;) tensor(43898.4336, grad_fn=&lt;MseLossBackward0&gt;) tensor(7646.8535, grad_fn=&lt;MseLossBackward0&gt;) tensor(1718.7260, grad_fn=&lt;MseLossBackward0&gt;) tensor(9952.3027, grad_fn=&lt;MseLossBackward0&gt;) tensor(29442.5723, grad_fn=&lt;MseLossBackward0&gt;) tensor(434.0549, grad_fn=&lt;MseLossBackward0&gt;) tensor(8710.5039, grad_fn=&lt;MseLossBackward0&gt;) tensor(19052.3555, grad_fn=&lt;MseLossBackward0&gt;) tensor(6065.9604, grad_fn=&lt;MseLossBackward0&gt;) tensor(3110.9487, grad_fn=&lt;MseLossBackward0&gt;) tensor(109.2678, grad_fn=&lt;MseLossBackward0&gt;) tensor(5956.2520, grad_fn=&lt;MseLossBackward0&gt;) tensor(20417.4512, grad_fn=&lt;MseLossBackward0&gt;) tensor(1736.3010, grad_fn=&lt;MseLossBackward0&gt;) tensor(1516.0909, grad_fn=&lt;MseLossBackward0&gt;) tensor(7944.1362, grad_fn=&lt;MseLossBackward0&gt;) tensor(23.6515, grad_fn=&lt;MseLossBackward0&gt;) tensor(297.6636, grad_fn=&lt;MseLossBackward0&gt;) tensor(2779.6785, grad_fn=&lt;MseLossBackward0&gt;) tensor(7844.5273, grad_fn=&lt;MseLossBackward0&gt;) tensor(11828.2617, grad_fn=&lt;MseLossBackward0&gt;) tensor(644.9814, grad_fn=&lt;MseLossBackward0&gt;) tensor(3045.9836, grad_fn=&lt;MseLossBackward0&gt;) tensor(2930.4670, grad_fn=&lt;MseLossBackward0&gt;) tensor(3197.6594, grad_fn=&lt;MseLossBackward0&gt;) tensor(13068.6875, grad_fn=&lt;MseLossBackward0&gt;) tensor(2035.1200, grad_fn=&lt;MseLossBackward0&gt;) tensor(4551.7686, grad_fn=&lt;MseLossBackward0&gt;) tensor(13338.1074, grad_fn=&lt;MseLossBackward0&gt;) tensor(3780.8689, grad_fn=&lt;MseLossBackward0&gt;) . . model(inp) . tensor([[5892.3145], [6237.1528], [6581.9897], [6926.8257], [7271.6616], [7616.4976], [7961.3335], [8306.1768], [8651.0127], [8995.8486]], grad_fn=&lt;AddmmBackward0&gt;) . . actual . tensor([[6000.0000], [6320.7002], [6641.4004], [6962.1006], [7282.8008], [7603.5010], [7924.2012], [8244.9014], [8565.6016], [8886.3018]]) . .",
            "url": "https://nakulpyasi.github.io/Unified-AI/jupyter/2022/08/14/_NN_FROM_SCRATCH_PYTORCH.html",
            "relUrl": "/jupyter/2022/08/14/_NN_FROM_SCRATCH_PYTORCH.html",
            "date": " • Aug 14, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://nakulpyasi.github.io/Unified-AI/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://nakulpyasi.github.io/Unified-AI/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nakulpyasi.github.io/Unified-AI/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nakulpyasi.github.io/Unified-AI/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}