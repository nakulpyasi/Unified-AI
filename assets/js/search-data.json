{
  
    
        "post0": {
            "title": "MNIST dataset - NN example - Gradient Descent - Feedforward NN - Pytorch",
            "content": ". Introduction . The MNIST database of handwritten digits. It has a training set of 60,000 examples, and a test set of 10,000 examples. The digits have been size-normalized and centered in a fixed-size image. | This code will help help you learn the technique of image classification using Pytorch | The problem that we are trying in this example - is to build a NN Model that can classify these handwritten images in the test set with maximum accuracy | . import torch import torchvision from torchvision.datasets import MNIST from torchvision.transforms import transforms import matplotlib.pyplot as plt from torch.utils.data import random_split from torch.utils.data import DataLoader import torch.nn as nn import torch.nn.functional as F from torchvision.utils import make_grid . # this line of code will download the images(60000) in the defined root folder # download = True - when ran once will nor re-download all the images if it finds the images in the root path # train = True means it is the training set dataset = MNIST(root=&#39;Deep_Learning_Explorations/data/&#39;,train = True, download=True,transform=transforms.ToTensor()) . # indexing the dataset will show us that # shape of the image is 1*28*28 # 28 * 28 are the pixel values ranging from values 0 to 1 # this image has a just one channel as it is a gray scale image img,label = dataset[89] # permute makes the channel dimension as the last dimension as it helps to visualize the image using plt.imshow img_viz = img.permute(1,2,0) plt.imshow(img_viz, cmap = &#39;gray&#39;); . img_viz = img.permute(1,2,0) print(img_viz.shape) # plt.imshow(img_viz, cmap = &#39;gray&#39;); . torch.Size([28, 28, 1]) . Split Dataset - Training and Validation . # Split the dataset into a training and the validation set tr_data, val_data = random_split(dataset,[50000,10000]) len(tr_data), len(val_data) . (50000, 10000) . . Training and Validation Dataloader . # Dataloader helps in converting the dataset into batches of data by describing the batch_size tr_loader = DataLoader(tr_data,batch_size=200,shuffle=True) val_loader = DataLoader(val_data,batch_size=200) . # We can see that the data is a batch of 128 images and 120 labels for data,label in tr_loader: print(data.shape) print(len(label)) break . torch.Size([200, 1, 28, 28]) 200 . . # x@w.t()+ bias - Use the same equation model = nn.Linear(in_features= 784,out_features=10) # A model will randomly initialize the parameters(wt&#39;s and biases) model.weight.shape, model.bias.shape . (torch.Size([10, 784]), torch.Size([10])) . . for img,label in tr_loader: # shape of the batch in the beggining print(img.shape) #this functionality can be added inside the model in the forward method img = img.reshape(-1,28*28) # shape after reshaping into a vector of 784 elements print(img.shape) # applying the model to the reshaped img pred = model(img) print(model(img).shape) # As we can see that the model has outputted 10 probabilities which is a prob for all elements from 0-9 break . torch.Size([200, 1, 28, 28]) torch.Size([200, 784]) torch.Size([200, 10]) . . print(pred) pred.shape . tensor([[-0.2481, -0.0215, 0.3545, ..., 0.0965, 0.0290, -0.0884], [ 0.0309, -0.2940, 0.3338, ..., -0.1401, 0.1159, -0.0594], [-0.1719, -0.2065, 0.3205, ..., 0.0377, -0.2394, -0.2114], ..., [-0.1821, 0.5084, 0.5995, ..., 0.0768, -0.3829, -0.1146], [ 0.1420, -0.0063, 0.0844, ..., 0.0449, -0.1514, -0.3190], [-0.2699, -0.2119, 0.2204, ..., 0.5135, -0.2199, -0.0297]], grad_fn=&lt;AddmmBackward0&gt;) . torch.Size([200, 10]) . . Additional functionality to our NN model . To add additional functionality to the NN model we need to create a MnistModel class and inheret the nn.Module. Addiditional functionality in this is the step of reshaping the batch of data passing through the model to a vector of 784 pixels . # To add additional functionality to a NN model - which is the reshaping of a bunch of images - we have the use the concepts of OOP and inheritance. The forward method is the one that is applied to the bunch of images class MnistModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(784, 10) def forward(self, xb): xb = xb.reshape(-1, 784) out = self.linear(xb) return out model = MnistModel() . model.linear.weight.shape, model.linear.bias.shape . (torch.Size([10, 784]), torch.Size([10])) . Softmax . Softmax converts a vector of K real numbers into a probability distribution of K possible outcomes . It is basically calculated by taking the exponent of preds and dividing by their sum to make sure its sum is 1 . for dta,label in tr_loader: pred = model(dta) print(pred.shape) print(label.shape) break # We will apply softmax now - which converts the probability b/w 0 and 1 and the sum is 1 torch.sum(F.softmax(pred[0])).item() # Applying softmax on the whole batch pred_s = F.softmax(pred,dim=1) # torch amx function gives us the index of the max probability as well as the probability index_prob,prob = torch.max(pred_s,dim=1) index_prob.shape,prob.shape . torch.Size([200, 10]) torch.Size([200]) . /var/folders/j4/0sh22ln930vdhyh1wkttl89m0000gp/T/ipykernel_30681/3939508011.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument. torch.sum(F.softmax(pred[0])).item() . (torch.Size([200]), torch.Size([200])) . Accuracy . The predictions are converted into probabilities and the highest probability is calculated using the max function . The index of the highest probability is then compared to the actual label and the accuracy % is calculated by divding the correct predictions with the total images . def metric_acc(outputs, labels): _, preds = torch.max(outputs, dim=1) return torch.tensor(torch.sum(preds == labels).item() / len(preds)) # We will get the same value even if we do not apply the softmax as # e^x is an increasing function, i.e., if y1 &gt; y2, then e^y1 &gt; e^y2. The same holds after averaging out the values to get the softmax. metric_acc(pred_s,label) . tensor(0.1050) . # loss function will be cross_entropy loss = F.cross_entropy(pred, label) print(loss) . tensor(2.2892, grad_fn=&lt;NllLossBackward0&gt;) . Model Training . This fit function is the training step. This training step invovles training the model on the training dataloader, calculating the loss, calculating the gradient for the train loader and updating the weights and reseting the gradient at the end. . For the second part of the loop - we validate the model on the validation dataloader. The steps include calculating the loss and accuracy after each epoch and printing them at the end. We can notice that the loss and the accuracy on the validation set improves after each epoch . class MnistModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(784, 10) def forward(self, xb): xb = xb.reshape(-1, 784) out = self.linear(xb) return out def results_epoch(out_lst): val_loss_epoch = torch.stack([dct[&#39;val_loss&#39;] for dct in out_lst]).mean() val_acc_epoch = torch.stack([dct[&#39;val_acc&#39;] for dct in out_lst]).mean() return {&#39;val_loss&#39;: val_loss_epoch.item(), &#39;val_acc&#39;: val_acc_epoch.item()} def final_output(dct,epoch): print(&quot;Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}&quot;.format(epoch, dct[&#39;val_loss&#39;], dct[&#39;val_acc&#39;])) def validation(batch_val,model): img_val,label_val = batch_val pred_val = model(img_val) # loss is computed loss_val = F.cross_entropy(pred_val,label_val) # Accuracy is computed acc_val = metric_acc(pred_val,label_val) return {&#39;val_loss&#39;: loss_val, &#39;val_acc&#39;: acc_val} def check_scores(val_loader,model): out_lst = [validation(batch_val,model) for batch_val in val_loader] return results_epoch(out_lst) def fit(epochs,learning_rate,model,train_loader,val_loader,opt_func=torch.optim.SGD): optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate , momentum=0.9) out_lst = [] for epoch in range(epochs): # Training step on the training dataloader for batch in tr_loader: #extract batch of images and label img,label = batch #calculate prediction using the MNISTMODEL class initialized above pred = model(img) #Since this is a multi-label image classification model- the loss function is cross entropy loss = F.cross_entropy(pred,label) # In this step we calculate the gradient of the loss function with respect to the parameters or 784 pixels in this case loss.backward() # In this step we update the weights optimizer.step() # We make the gradient zero again so that now the gradients are not calculated untill the training is not done optimizer.zero_grad() # Validation on the validation dataloader output = check_scores(val_loader,model) out_lst.append(output) final_output(output,epoch) return out_lst . model = MnistModel() starting = check_scores(val_loader,model) print(starting) out_lst = fit(20,learning_rate=0.002,model= model,train_loader = tr_loader,val_loader = val_loader) . {&#39;val_loss&#39;: 2.3094968795776367, &#39;val_acc&#39;: 0.10899999737739563} Epoch [0], val_loss: 0.8053, val_acc: 0.8323 Epoch [1], val_loss: 0.6180, val_acc: 0.8553 Epoch [2], val_loss: 0.5429, val_acc: 0.8651 Epoch [3], val_loss: 0.5003, val_acc: 0.8737 Epoch [4], val_loss: 0.4718, val_acc: 0.8784 Epoch [5], val_loss: 0.4517, val_acc: 0.8802 Epoch [6], val_loss: 0.4362, val_acc: 0.8818 Epoch [7], val_loss: 0.4241, val_acc: 0.8847 Epoch [8], val_loss: 0.4138, val_acc: 0.8873 Epoch [9], val_loss: 0.4054, val_acc: 0.8888 Epoch [10], val_loss: 0.3983, val_acc: 0.8905 Epoch [11], val_loss: 0.3922, val_acc: 0.8915 Epoch [12], val_loss: 0.3866, val_acc: 0.8925 Epoch [13], val_loss: 0.3814, val_acc: 0.8942 Epoch [14], val_loss: 0.3772, val_acc: 0.8945 Epoch [15], val_loss: 0.3733, val_acc: 0.8947 Epoch [16], val_loss: 0.3696, val_acc: 0.8968 Epoch [17], val_loss: 0.3666, val_acc: 0.8971 Epoch [18], val_loss: 0.3636, val_acc: 0.8972 Epoch [19], val_loss: 0.3605, val_acc: 0.8984 . history = [starting] + out_lst accuracies = [result[&#39;val_acc&#39;] for result in history] print(accuracies) . [0.10899999737739563, 0.8323000073432922, 0.8553000688552856, 0.8651000261306763, 0.8737000226974487, 0.8783999681472778, 0.8802000284194946, 0.8817999362945557, 0.8846999406814575, 0.8872999548912048, 0.8888000249862671, 0.8904999494552612, 0.8914999961853027, 0.892500102519989, 0.8941999673843384, 0.8945000171661377, 0.8947001099586487, 0.8968001008033752, 0.8970999717712402, 0.8972001075744629, 0.898400068283081] . Visualization . This visualization shows us how much the model learns with each epoch . plt.plot(accuracies,&#39;-X&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;accuracy_on_the_validation_set&#39;) . Text(0, 0.5, &#39;accuracy_on_the_validation_set&#39;) . We can clearly see that with each epoch the loss and accuracies improve. You can try to use different number of epochs and learning rate to see if you can improve the accuracy . Testing on the test set . img_test = MNIST(root=&#39;Deep_Learning_Explorations/data/&#39;,train = False,transform=transforms.ToTensor()) . Prediction Function on the test set . def pred_function(img,model): img.shape inp = img.unsqueeze(0) out = model(inp) prob , preds = torch.max(out,dim=1) return preds[0].item() . img, label = img_test[200] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label, &#39;, Predicted:&#39;, pred_function(img, model)) . Label: 3 , Predicted: 3 . img, label = img_test[123] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label, &#39;, Predicted:&#39;, pred_function(img, model)) . Label: 6 , Predicted: 6 . Testing on all images - the test set . test_loader = DataLoader(img_test, batch_size=20) . check_scores(test_loader,model) . {&#39;val_loss&#39;: 0.3312353193759918, &#39;val_acc&#39;: 0.9093000292778015} . Feed-Forward NN - Adding non-linearity to further improve the model . class MnistModel(nn.Module): def __init__(self): super().__init__() self.linear1 = nn.Linear(784, 90) self.linear2 = nn.Linear(90,10) def forward(self, xb): xb = xb.view(xb.size(0),-1) out = self.linear1(xb) out = F.relu(out) out = self.linear2(out) return out model = MnistModel() . # We can see the weights and params of the different layers below for param in model.parameters(): print(param.shape) . torch.Size([90, 784]) torch.Size([90]) torch.Size([10, 90]) torch.Size([10]) . model.linear1.weight.shape,model.linear2.weight.shape . (torch.Size([90, 784]), torch.Size([10, 90])) . Model Validation Feed-Forward Neural Network . We can observe that just by adding more linear layers and non-linearity to the model the accuracy of the model improves on the training and the test set . for images, _ in tr_loader: print(&#39;images.shape:&#39;, images.shape) plt.figure(figsize=(8,8)) plt.axis(&#39;off&#39;) plt.imshow(make_grid(images, nrow=14).permute((1, 2, 0))) break . images.shape: torch.Size([200, 1, 28, 28]) . model = MnistModel() starting = check_scores(val_loader,model) print(starting) out_lst = fit(20,learning_rate=0.002,model= model,train_loader = tr_loader,val_loader = val_loader) . {&#39;val_loss&#39;: 2.2920496463775635, &#39;val_acc&#39;: 0.13729999959468842} Epoch [0], val_loss: 1.0469, val_acc: 0.7977 Epoch [1], val_loss: 0.5957, val_acc: 0.8539 Epoch [2], val_loss: 0.4784, val_acc: 0.8716 Epoch [3], val_loss: 0.4247, val_acc: 0.8811 Epoch [4], val_loss: 0.3936, val_acc: 0.8874 Epoch [5], val_loss: 0.3723, val_acc: 0.8913 Epoch [6], val_loss: 0.3566, val_acc: 0.8956 Epoch [7], val_loss: 0.3426, val_acc: 0.8996 Epoch [8], val_loss: 0.3320, val_acc: 0.9033 Epoch [9], val_loss: 0.3237, val_acc: 0.9055 Epoch [10], val_loss: 0.3146, val_acc: 0.9080 Epoch [11], val_loss: 0.3078, val_acc: 0.9108 Epoch [12], val_loss: 0.3003, val_acc: 0.9131 Epoch [13], val_loss: 0.2949, val_acc: 0.9140 Epoch [14], val_loss: 0.2899, val_acc: 0.9166 Epoch [15], val_loss: 0.2838, val_acc: 0.9164 Epoch [16], val_loss: 0.2783, val_acc: 0.9198 Epoch [17], val_loss: 0.2733, val_acc: 0.9207 Epoch [18], val_loss: 0.2682, val_acc: 0.9225 Epoch [19], val_loss: 0.2638, val_acc: 0.9239 . Result on the test set . check_scores(test_loader,model) . {&#39;val_loss&#39;: 0.2418811321258545, &#39;val_acc&#39;: 0.9318000078201294} .",
            "url": "https://nakulpyasi.github.io/Unified-AI/jupyter/2022/08/22/feed_forward.html",
            "relUrl": "/jupyter/2022/08/22/feed_forward.html",
            "date": " • Aug 22, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "MNIST dataset - NN example(Pytorch)",
            "content": ". import torch import torchvision from torchvision.datasets import MNIST from torchvision.transforms import transforms import matplotlib.pyplot as plt from torch.utils.data import random_split from torch.utils.data import DataLoader import torch.nn as nn import torch.nn.functional as F . # this line of code will download the images(60000) in the defined root folder # download = True - when ran once will nor re-download all the images if it finds the images in the root path # train = True means it is the training set dataset = MNIST(root=&#39;Deep_Learning_Explorations/data/&#39;,train = True, download=True,transform=transforms.ToTensor()) # Dataset is a tuple of image and the label # indexing the dataset will show us that # shape of thwe image is 1*28*28 # 28 * 28 are the pixel values ranging from values 0 to 1 # this image has a just one channel as it is a gray scale image type(dataset[0][0]), type(dataset[0][1]), dataset[0][0].shape . (torch.Tensor, int, torch.Size([1, 28, 28])) . plt.imshow(dataset[0][0], cmap = &#39;gray&#39;); . Split Dataset - Training and Validation . # Split the dataset into a training and the validation set tr_data, val_data = random_split(dataset,[50000,10000]) len(tr_data), len(val_data) . (50000, 10000) . . Training and Validation Dataloader . # Dataloader helps in converting the dataset into batches of data by describing the batch_size tr_loader = DataLoader(tr_data,batch_size=200,shuffle=True) val_loader = DataLoader(val_data,batch_size=200) . # We can see that the data is a batch of 128 images and 120 labels for data,label in tr_loader: print(data.shape) print(len(label)) break . torch.Size([200, 1, 28, 28]) 200 . . # x@w.t()+ bias - Use the same equation model = nn.Linear(in_features= 784,out_features=10) # A model will randomly initialize the parameters(wt&#39;s and biases) model.weight.shape, model.bias.shape . (torch.Size([10, 784]), torch.Size([10])) . . for img,label in tr_loader: # shape of the batch in the beggining print(img.shape) #this functionality can be added inside the model in the forward method img = img.reshape(-1,28*28) # shape after reshaping into a vector of 784 elements print(img.shape) # applying the model to the reshaped img pred = model(img) print(model(img).shape) # As we can see that the model has outputted 10 probabilities which is a prob for all elements from 0-9 break . torch.Size([200, 1, 28, 28]) torch.Size([200, 784]) torch.Size([200, 10]) . . print(pred) pred.shape . tensor([[-0.1780, -0.2030, -0.1832, ..., -0.0791, 0.1601, -0.0289], [-0.0835, -0.3761, -0.2121, ..., -0.2008, -0.2714, -0.2222], [-0.0419, -0.1072, -0.0031, ..., -0.1503, 0.0071, -0.1969], ..., [-0.1106, -0.1116, 0.1379, ..., -0.0675, -0.0677, 0.0206], [-0.0918, -0.1213, -0.0014, ..., -0.1266, 0.1137, 0.3449], [-0.2163, 0.0296, 0.0380, ..., -0.0783, -0.1645, -0.1849]], grad_fn=&lt;AddmmBackward0&gt;) . torch.Size([200, 10]) . . Additional functionality to our NN model . To add additional functionality to the NN model we need to create a MnistModel class and inheret the nn.Module. Addiditional functionality in this is the step of reshaping the batch of data passing through the model to a vector of 784 pixels . class MnistModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(784, 10) def forward(self, xb): xb = xb.reshape(-1, 784) out = self.linear(xb) return out model = MNIST() . model.layer.weight.shape, model.layer.bias.shape . (torch.Size([10, 784]), torch.Size([10])) . Sofmax . Softmax converts a vector of K real numbers into a probability distribution of K possible outcomes . It is basically calculated by taking the exponent of preds and dividing by their sum to make sure its sum is 1 . for dta,label in tr_loader: pred = model(dta) print(pred.shape) print(label.shape) break # We will apply softmax now - which converts the probability b/w 0 and 1 and the sum is 1 torch.sum(F.softmax(pred[0])).item() # Applying softmax on the whole batch pred_s = F.softmax(pred,dim=1) # torch amx function gives us the index of the max probability as well as the probability index_prob,prob = torch.max(pred_s,dim=1) index_prob.shape,prob.shape . torch.Size([200, 10]) torch.Size([200]) . /var/folders/j4/0sh22ln930vdhyh1wkttl89m0000gp/T/ipykernel_24095/3939508011.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument. torch.sum(F.softmax(pred[0])).item() . (torch.Size([200]), torch.Size([200])) . Accuracy . The predictions are converted into probabilities and the highest probability is calculated using the max function . The index of the highest probability is then compared to the actual label and the accuracy % is calculated by divding the correct predictions with the total images . def metric_acc(out,label): index_prob,prob = torch.max(pred_s,dim=1) return torch.sum(prob==label)/prob.numel() # We will get the same value even if we do not apply the softmax as # e^x is an increasing function, i.e., if y1 &gt; y2, then e^y1 &gt; e^y2. The same holds after averaging out the values to get the softmax. metric_acc(prob,label) . tensor(0.0700) . # loss function will be cross_entropy loss = F.cross_entropy(pred, label) print(loss) . tensor(2.3289, grad_fn=&lt;NllLossBackward0&gt;) . Model Training . This fit function is the training step. This training step invovles training the model on the training dataloader, calculating the loss, calculating the gradient for the train loader and updating the weights and reseting the gradient at the end. . For the second part of the loop - we validate the model on the validation dataloader. The steps include calculating the loss and accuracy after each epoch and printing them at the end. We can notice that the loss and the accuracy on the validation set improves after each epoch . def fit(epochs,learning_rate,model,train_loader,val_loader,opt_func=torch.optim.SGD): optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate , momentum=0.9) out_lst = [] for epoch in range(epochs): # Training step on the training dataloader for batch in tr_loader: #extract batch of images and label img,label = batch #calculate prediction using the MNISTMODEL class initialized above pred = model(img) #Since this is a multi-label image classification model- the loss function is cross entropy loss = F.cross_entropy(pred,label) # In this step we calculate the gradient of the loss function with respect to the parameters or 784 pixels in this case loss.backward() # In this step we update the weights optimizer.step() # We make the gradient zero again so that now the gradients are not calculated untill the training is not done optimizer.zero_grad() # Validation on the validation dataloader for batch_val in val_loader: img_val,label_val = batch_val pred_val = model(img_val) # loss is computed loss_val = F.cross_entropy(pred_val,label_val) # Accuracy is computed acc_val = metric_acc(pred_val,label_val) out_lst.append({&#39;Epoch&#39;:epoch,&#39;val_loss&#39;: loss_val, &#39;val_acc&#39;: acc_val}) # Accuracies and loss are stacked together for each epoch, mean is calculated and the results are printed val_loss_epoch = torch.stack([dct[&#39;val_loss&#39;] for dct in out_lst]).mean() val_acc_epoch = torch.stack([dct[&#39;val_acc&#39;] for dct in out_lst]).mean() print(&#39;Epoch: {0}, loss: {1}, accuracy_val: {2}&#39;.format(epoch,val_loss_epoch,val_acc_epoch)) model = MnistModel() . We can clearly see that with each epoch the loss and accuracies improve. You can try to use different number of epochs and learning rate to see if you can improve the accuracy . fit(20,learning_rate=0.005,model= model,train_loader = tr_loader,val_loader = val_loader) . Epoch: 0, loss: 0.5632244348526001, accuracy_val: 0.861500084400177 Epoch: 1, loss: 0.5117447376251221, accuracy_val: 0.8712499737739563 Epoch: 2, loss: 0.4806540310382843, accuracy_val: 0.8765000700950623 Epoch: 3, loss: 0.45891621708869934, accuracy_val: 0.8803249597549438 Epoch: 4, loss: 0.44262486696243286, accuracy_val: 0.8833799362182617 Epoch: 5, loss: 0.4297642111778259, accuracy_val: 0.885816752910614 Epoch: 6, loss: 0.4192468225955963, accuracy_val: 0.8878857493400574 Epoch: 7, loss: 0.41042187809944153, accuracy_val: 0.889549970626831 Epoch: 8, loss: 0.4029468595981598, accuracy_val: 0.891033411026001 Epoch: 9, loss: 0.3964667320251465, accuracy_val: 0.8922899961471558 Epoch: 10, loss: 0.3907521069049835, accuracy_val: 0.8933908939361572 Epoch: 11, loss: 0.385611355304718, accuracy_val: 0.8943833708763123 Epoch: 12, loss: 0.38104525208473206, accuracy_val: 0.8952845931053162 Epoch: 13, loss: 0.37690234184265137, accuracy_val: 0.8960857391357422 Epoch: 14, loss: 0.37316834926605225, accuracy_val: 0.8968601226806641 Epoch: 15, loss: 0.3697192370891571, accuracy_val: 0.8975686430931091 Epoch: 16, loss: 0.36654046177864075, accuracy_val: 0.8981589078903198 Epoch: 17, loss: 0.3636338710784912, accuracy_val: 0.8987833857536316 Epoch: 18, loss: 0.3609280586242676, accuracy_val: 0.8993525505065918 Epoch: 19, loss: 0.35844382643699646, accuracy_val: 0.899869978427887 . . Testing on the test set . img_test = MNIST(root=&#39;Deep_Learning_Explorations/data/&#39;,train = False,transform=transforms.ToTensor()) . # gray scale has just 1 channnel # 1*28*28, 1 here specifies that image has just one channel img, label = img_test[12] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;Shape:&#39;, img.shape) print(&#39;Label:&#39;, label) . Shape: torch.Size([1, 28, 28]) Label: 9 . Prediction Function on the test set . def pred_function(img,model): img.shape inp = img.unsqueeze(0) out = model(inp) prob , preds = torch.max(out,dim=1) return preds[0].item() . img, label = img_test[200] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label, &#39;, Predicted:&#39;, pred_function(img, model)) . Label: 3 , Predicted: 3 . img, label = img_test[123] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label, &#39;, Predicted:&#39;, pred_function(img, model)) . Label: 6 , Predicted: 6 . Testing on all images - the test set . test_loader = DataLoader(img_test, batch_size=20) # pass the batches to the model and calculate model accuracy and loss def test_set_preds(test_loader,model): out_lst = [] for i, batch_val in enumerate(test_loader): img_val,label_val = batch_val pred_val = model(img_val) # loss is computed for that batch loss_val = F.cross_entropy(pred_val,label_val) # Accuracy is computed for that batch acc_val = metric_acc(pred_val,label_val) out_lst.append({&#39;val_loss&#39;: loss_val, &#39;val_acc&#39;: acc_val}) #Accuracies and loss are stacked together for each epoch, mean is calculated and the results are printed final_loss = torch.stack([dct[&#39;val_loss&#39;] for dct in out_lst]).mean() final_acc= torch.stack([dct[&#39;val_acc&#39;] for dct in out_lst]).mean() return &#39;loss: {0}, accuracy_val: {1}&#39;.format(final_loss,final_acc) . test_set_preds(test_loader,model) . &#39;loss: 0.297660231590271, accuracy_val: 0.9175999164581299&#39; .",
            "url": "https://nakulpyasi.github.io/Unified-AI/jupyter/2022/08/19/MNIST-Pytorch.html",
            "relUrl": "/jupyter/2022/08/19/MNIST-Pytorch.html",
            "date": " • Aug 19, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Gradient Descent from Scratch using Pytorch",
            "content": ". This notebook is an implementation of a gradient descent using PYTORCH . gradient_descent is the foundation of all deep learning problems. It is super critical tp understand this . import numpy as np import torch import pandas as pd from torch.utils.data import TensorDataset from torch.utils.data import DataLoader from torch.utils.data import random_split import torch.nn as nn import torch.nn.functional as F . inp = np.arange(58,387,step = 5.5, dtype=np.float32).reshape(10,6) inp . array([[ 58. , 63.5, 69. , 74.5, 80. , 85.5], [ 91. , 96.5, 102. , 107.5, 113. , 118.5], [124. , 129.5, 135. , 140.5, 146. , 151.5], [157. , 162.5, 168. , 173.5, 179. , 184.5], [190. , 195.5, 201. , 206.5, 212. , 217.5], [223. , 228.5, 234. , 239.5, 245. , 250.5], [256. , 261.5, 267. , 272.5, 278. , 283.5], [289. , 294.5, 300. , 305.5, 311. , 316.5], [322. , 327.5, 333. , 338.5, 344. , 349.5], [355. , 360.5, 366. , 371.5, 377. , 382.5]], dtype=float32) . . inp.dtype, inp.shape . (dtype(&#39;float32&#39;), (10, 6)) . . actual = np.arange(6000,9000,step = 320.7,dtype=np.float32).reshape(10,1) actual . array([[6000. ], [6320.7 ], [6641.4004], [6962.1006], [7282.801 ], [7603.501 ], [7924.201 ], [8244.901 ], [8565.602 ], [8886.302 ]], dtype=float32) . . actual.dtype, actual.shape . (dtype(&#39;float32&#39;), (10, 1)) . . inp= torch.from_numpy(inp) actual = torch.from_numpy(actual) . Convert to dataset and dataloader . ds = TensorDataset(inp, actual) # To divide the data into train and validation set we use random_split # [8,2] splits the data into training and validation dataset #tr_dataset, val_dataset = random_split(ds,[8,2]) # Dataloader helps to split data into batches and shuffling the data train_loader = DataLoader(ds, shuffle=True) # datatypes of dataset an train_loader type(ds) , type(train_loader) . (torch.utils.data.dataset.TensorDataset, torch.utils.data.dataloader.DataLoader) . A dataloader always gives a tuple of the training data and the label with it . #Iteration to see what a dataloader provides for data,label in train_loader: print(data) print(label) . tensor([[190.0000, 195.5000, 201.0000, 206.5000, 212.0000, 217.5000]]) tensor([[7282.8008]]) tensor([[322.0000, 327.5000, 333.0000, 338.5000, 344.0000, 349.5000]]) tensor([[8565.6016]]) tensor([[ 91.0000, 96.5000, 102.0000, 107.5000, 113.0000, 118.5000]]) tensor([[6320.7002]]) tensor([[256.0000, 261.5000, 267.0000, 272.5000, 278.0000, 283.5000]]) tensor([[7924.2012]]) tensor([[124.0000, 129.5000, 135.0000, 140.5000, 146.0000, 151.5000]]) tensor([[6641.4004]]) tensor([[289.0000, 294.5000, 300.0000, 305.5000, 311.0000, 316.5000]]) tensor([[8244.9014]]) tensor([[58.0000, 63.5000, 69.0000, 74.5000, 80.0000, 85.5000]]) tensor([[6000.]]) tensor([[355.0000, 360.5000, 366.0000, 371.5000, 377.0000, 382.5000]]) tensor([[8886.3018]]) tensor([[157.0000, 162.5000, 168.0000, 173.5000, 179.0000, 184.5000]]) tensor([[6962.1006]]) tensor([[223.0000, 228.5000, 234.0000, 239.5000, 245.0000, 250.5000]]) tensor([[7603.5010]]) . . Create a model using NN.Linear and pass the input through it to generate to produce the output . # inputs are the number of columns in a tabular dataset # outputs can be the number of outputs input_size = 6 output_size = 1 model = nn.Linear(input_size,output_size) # To look at the weight and bias use a parameter method list(model.parameters()) # using the model to generate predictions predictions = model(inp) . actual.shape, predictions.shape . (torch.Size([10, 1]), torch.Size([10, 1])) . Calculate the loss . # Now the loss function can be computed by directly using F.mse_loss loss = F.mse_loss(predictions,actual) # Models wts and bias can be updated automatically using a optimizer opt = torch.optim.SGD(model.parameters(),lr = 1e-6) opt . SGD ( Parameter Group 0 dampening: 0 lr: 1e-06 maximize: False momentum: 0 nesterov: False weight_decay: 0 ) . . Run the process of Gradient_Descent to find optimal weights and bias . # Steps for nn implementation num_epochs = 2000 for epoch in range(num_epochs): for data,label in train_loader: # preds preds = model(data) # calculate loss loss = F.mse_loss(preds,label) # gradient calculation loss.backward() # update wts and bias wrt loss opt.step() # gradients values are 0 again opt.zero_grad() if epoch%30==0: print(loss) . tensor(1276.5966, grad_fn=&lt;MseLossBackward0&gt;) tensor(2668.6709, grad_fn=&lt;MseLossBackward0&gt;) tensor(7169.9878, grad_fn=&lt;MseLossBackward0&gt;) tensor(469.6278, grad_fn=&lt;MseLossBackward0&gt;) tensor(6568.8335, grad_fn=&lt;MseLossBackward0&gt;) tensor(1190.0479, grad_fn=&lt;MseLossBackward0&gt;) tensor(325.2668, grad_fn=&lt;MseLossBackward0&gt;) tensor(5114.6245, grad_fn=&lt;MseLossBackward0&gt;) tensor(1722.8174, grad_fn=&lt;MseLossBackward0&gt;) tensor(1077.5576, grad_fn=&lt;MseLossBackward0&gt;) tensor(160.6259, grad_fn=&lt;MseLossBackward0&gt;) tensor(375.2014, grad_fn=&lt;MseLossBackward0&gt;) tensor(4391.7803, grad_fn=&lt;MseLossBackward0&gt;) tensor(2078.6121, grad_fn=&lt;MseLossBackward0&gt;) tensor(2570.0146, grad_fn=&lt;MseLossBackward0&gt;) tensor(725.0766, grad_fn=&lt;MseLossBackward0&gt;) tensor(2081.1060, grad_fn=&lt;MseLossBackward0&gt;) tensor(873.6527, grad_fn=&lt;MseLossBackward0&gt;) tensor(83.2389, grad_fn=&lt;MseLossBackward0&gt;) tensor(1916.8406, grad_fn=&lt;MseLossBackward0&gt;) tensor(719.1458, grad_fn=&lt;MseLossBackward0&gt;) tensor(1902.9702, grad_fn=&lt;MseLossBackward0&gt;) tensor(42.3262, grad_fn=&lt;MseLossBackward0&gt;) tensor(763.7343, grad_fn=&lt;MseLossBackward0&gt;) tensor(365.8590, grad_fn=&lt;MseLossBackward0&gt;) tensor(112.0207, grad_fn=&lt;MseLossBackward0&gt;) tensor(925.1934, grad_fn=&lt;MseLossBackward0&gt;) tensor(158.8609, grad_fn=&lt;MseLossBackward0&gt;) tensor(363.2858, grad_fn=&lt;MseLossBackward0&gt;) tensor(0.4345, grad_fn=&lt;MseLossBackward0&gt;) tensor(453.9729, grad_fn=&lt;MseLossBackward0&gt;) tensor(123.0280, grad_fn=&lt;MseLossBackward0&gt;) tensor(30.7137, grad_fn=&lt;MseLossBackward0&gt;) tensor(350.9402, grad_fn=&lt;MseLossBackward0&gt;) tensor(89.2324, grad_fn=&lt;MseLossBackward0&gt;) tensor(296.6872, grad_fn=&lt;MseLossBackward0&gt;) tensor(19.0595, grad_fn=&lt;MseLossBackward0&gt;) tensor(20.8788, grad_fn=&lt;MseLossBackward0&gt;) tensor(83.6939, grad_fn=&lt;MseLossBackward0&gt;) tensor(173.1255, grad_fn=&lt;MseLossBackward0&gt;) tensor(155.1168, grad_fn=&lt;MseLossBackward0&gt;) tensor(125.8494, grad_fn=&lt;MseLossBackward0&gt;) tensor(179.1650, grad_fn=&lt;MseLossBackward0&gt;) tensor(92.3213, grad_fn=&lt;MseLossBackward0&gt;) tensor(23.1508, grad_fn=&lt;MseLossBackward0&gt;) tensor(34.4067, grad_fn=&lt;MseLossBackward0&gt;) tensor(54.5636, grad_fn=&lt;MseLossBackward0&gt;) tensor(18.6440, grad_fn=&lt;MseLossBackward0&gt;) tensor(145.8339, grad_fn=&lt;MseLossBackward0&gt;) tensor(47.0510, grad_fn=&lt;MseLossBackward0&gt;) tensor(21.9315, grad_fn=&lt;MseLossBackward0&gt;) tensor(59.0601, grad_fn=&lt;MseLossBackward0&gt;) tensor(5.9200, grad_fn=&lt;MseLossBackward0&gt;) tensor(27.8658, grad_fn=&lt;MseLossBackward0&gt;) tensor(23.2401, grad_fn=&lt;MseLossBackward0&gt;) tensor(2.5090, grad_fn=&lt;MseLossBackward0&gt;) tensor(5.5459, grad_fn=&lt;MseLossBackward0&gt;) tensor(12.6879, grad_fn=&lt;MseLossBackward0&gt;) tensor(32.2145, grad_fn=&lt;MseLossBackward0&gt;) tensor(31.1918, grad_fn=&lt;MseLossBackward0&gt;) tensor(1.8559, grad_fn=&lt;MseLossBackward0&gt;) tensor(14.7257, grad_fn=&lt;MseLossBackward0&gt;) tensor(8.5545, grad_fn=&lt;MseLossBackward0&gt;) tensor(6.6442, grad_fn=&lt;MseLossBackward0&gt;) tensor(18.0003, grad_fn=&lt;MseLossBackward0&gt;) tensor(11.6892, grad_fn=&lt;MseLossBackward0&gt;) tensor(1.4676, grad_fn=&lt;MseLossBackward0&gt;) . . Now we can compare the results obtained by the model after the weights are updated and gradient_descent is run . We can see that we are quite close to the actual value . # predictions after the weights are updated model(inp) . tensor([[5996.6123], [6318.0566], [6639.5049], [6960.9502], [7282.3916], [7603.8350], [7925.2881], [8246.7295], [8568.1748], [8889.6162]], grad_fn=&lt;AddmmBackward0&gt;) . . # Actual values from the model actual . tensor([[6000.0000], [6320.7002], [6641.4004], [6962.1006], [7282.8008], [7603.5010], [7924.2012], [8244.9014], [8565.6016], [8886.3018]]) . .",
            "url": "https://nakulpyasi.github.io/Unified-AI/jupyter/2022/08/15/NN.html",
            "relUrl": "/jupyter/2022/08/15/NN.html",
            "date": " • Aug 15, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://nakulpyasi.github.io/Unified-AI/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://nakulpyasi.github.io/Unified-AI/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nakulpyasi.github.io/Unified-AI/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nakulpyasi.github.io/Unified-AI/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}