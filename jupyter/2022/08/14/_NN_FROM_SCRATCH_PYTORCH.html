<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Gradient Descent from Scratch using Pytorch | Unified-AI-Blogs</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Gradient Descent from Scratch using Pytorch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A tutorial of gradient descent from scratch using pytorch" />
<meta property="og:description" content="A tutorial of gradient descent from scratch using pytorch" />
<link rel="canonical" href="https://nakulpyasi.github.io/Unified-AI/jupyter/2022/08/14/_NN_FROM_SCRATCH_PYTORCH.html" />
<meta property="og:url" content="https://nakulpyasi.github.io/Unified-AI/jupyter/2022/08/14/_NN_FROM_SCRATCH_PYTORCH.html" />
<meta property="og:site_name" content="Unified-AI-Blogs" />
<meta property="og:image" content="https://nakulpyasi.github.io/Unified-AI/images/nn_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-14T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://nakulpyasi.github.io/Unified-AI/images/nn_image.png" />
<meta property="twitter:title" content="Gradient Descent from Scratch using Pytorch" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-08-14T00:00:00-05:00","datePublished":"2022-08-14T00:00:00-05:00","description":"A tutorial of gradient descent from scratch using pytorch","headline":"Gradient Descent from Scratch using Pytorch","image":"https://nakulpyasi.github.io/Unified-AI/images/nn_image.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://nakulpyasi.github.io/Unified-AI/jupyter/2022/08/14/_NN_FROM_SCRATCH_PYTORCH.html"},"url":"https://nakulpyasi.github.io/Unified-AI/jupyter/2022/08/14/_NN_FROM_SCRATCH_PYTORCH.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Unified-AI/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nakulpyasi.github.io/Unified-AI/feed.xml" title="Unified-AI-Blogs" /><link rel="shortcut icon" type="image/x-icon" href="/Unified-AI/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Unified-AI/">Unified-AI-Blogs</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Unified-AI/about/">About Me</a><a class="page-link" href="/Unified-AI/search/">Search</a><a class="page-link" href="/Unified-AI/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Gradient Descent from Scratch using Pytorch</h1><p class="page-description">A tutorial of gradient descent from scratch using pytorch</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-14T00:00:00-05:00" itemprop="datePublished">
        Aug 14, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Unified-AI/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/nakulpyasi/Unified-AI/tree/master/_notebooks/2022-08-15_NN_FROM_SCRATCH_PYTORCH.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Unified-AI/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/nakulpyasi/Unified-AI/master?filepath=_notebooks%2F2022-08-15_NN_FROM_SCRATCH_PYTORCH.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Unified-AI/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/nakulpyasi/Unified-AI/blob/master/_notebooks/2022-08-15_NN_FROM_SCRATCH_PYTORCH.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Unified-AI/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fnakulpyasi%2FUnified-AI%2Fblob%2Fmaster%2F_notebooks%2F2022-08-15_NN_FROM_SCRATCH_PYTORCH.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/Unified-AI/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-08-15_NN_FROM_SCRATCH_PYTORCH.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This notebook is an implementation of a gradient descent using PYTORCH</p>
<p><code>gradient_descent</code> is the foundation of all deep learning problems. It is super critical tp understand this</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="kn">import</span>  <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nnß</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">58</span><span class="p">,</span><span class="mi">387</span><span class="p">,</span><span class="n">step</span> <span class="o">=</span> <span class="mf">5.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span>
<span class="n">inp</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[ 58. ,  63.5,  69. ,  74.5,  80. ,  85.5],
       [ 91. ,  96.5, 102. , 107.5, 113. , 118.5],
       [124. , 129.5, 135. , 140.5, 146. , 151.5],
       [157. , 162.5, 168. , 173.5, 179. , 184.5],
       [190. , 195.5, 201. , 206.5, 212. , 217.5],
       [223. , 228.5, 234. , 239.5, 245. , 250.5],
       [256. , 261.5, 267. , 272.5, 278. , 283.5],
       [289. , 294.5, 300. , 305.5, 311. , 316.5],
       [322. , 327.5, 333. , 338.5, 344. , 349.5],
       [355. , 360.5, 366. , 371.5, 377. , 382.5]], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6000</span><span class="p">,</span><span class="mi">9000</span><span class="p">,</span><span class="n">step</span> <span class="o">=</span> <span class="mf">320.7</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">actual</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">actual</span><span class="o">.</span><span class="n">shape</span>
<span class="n">actual</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[6000.    ],
       [6320.7   ],
       [6641.4004],
       [6962.1006],
       [7282.801 ],
       [7603.501 ],
       [7924.201 ],
       [8244.901 ],
       [8565.602 ],
       [8886.302 ]], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span>

<span class="c1"># To divide the data into train and validation set we use random_split</span>
<span class="c1"># [8,2] splits the data into training and validation dataset</span>
<span class="c1">#tr_dataset, val_dataset = random_split(ds,[8,2])</span>

<span class="c1"># Dataloader helps to split data into batches and shuffling the data</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># datatypes of dataset an train_loader</span>
<span class="nb">type</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span> <span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.utils.data.dataset.TensorDataset,
 torch.utils.data.dataloader.DataLoader)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Iteration to see what a dataloader provides</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
</p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[157.0000, 162.5000, 168.0000, 173.5000, 179.0000, 184.5000]])
tensor([[6962.1006]])
tensor([[355.0000, 360.5000, 366.0000, 371.5000, 377.0000, 382.5000]])
tensor([[8886.3018]])
tensor([[322.0000, 327.5000, 333.0000, 338.5000, 344.0000, 349.5000]])
tensor([[8565.6016]])
tensor([[190.0000, 195.5000, 201.0000, 206.5000, 212.0000, 217.5000]])
tensor([[7282.8008]])
tensor([[256.0000, 261.5000, 267.0000, 272.5000, 278.0000, 283.5000]])
tensor([[7924.2012]])
tensor([[124.0000, 129.5000, 135.0000, 140.5000, 146.0000, 151.5000]])
tensor([[6641.4004]])
tensor([[289.0000, 294.5000, 300.0000, 305.5000, 311.0000, 316.5000]])
tensor([[8244.9014]])
tensor([[ 91.0000,  96.5000, 102.0000, 107.5000, 113.0000, 118.5000]])
tensor([[6320.7002]])
tensor([[58.0000, 63.5000, 69.0000, 74.5000, 80.0000, 85.5000]])
tensor([[6000.]])
tensor([[223.0000, 228.5000, 234.0000, 239.5000, 245.0000, 250.5000]])
tensor([[7603.5010]])
</pre>
</div>
</div>

</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># inputs are the number of columns in a tabular dataset</span>
<span class="c1"># outputs can be the number of outputs</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span><span class="n">output_size</span><span class="p">)</span>

<span class="c1"># To look at the weight and bias use a parameter method</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="c1"># using the model to generate predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">actual</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">predictions</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([10, 1]), torch.Size([10, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span><span class="n">actual</span><span class="p">)</span>

<span class="c1"># Models wts and bias can be updated automatically using a optimizer</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Steps for nn implementation</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span><span class="n">label</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># preds</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># calculate loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span><span class="n">label</span><span class="p">)</span>
        <span class="c1"># gradient calculation</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># update wts and bias wrt loss</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># gradients values are 0 again</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">10</span>==0:
        <span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
</p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(1025286.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1841393.3750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(9880742., grad_fn=&lt;MseLossBackward0&gt;)
tensor(15824849., grad_fn=&lt;MseLossBackward0&gt;)
tensor(12866921., grad_fn=&lt;MseLossBackward0&gt;)
tensor(1403273.8750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(6889109., grad_fn=&lt;MseLossBackward0&gt;)
tensor(301995.3125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(7300813., grad_fn=&lt;MseLossBackward0&gt;)
tensor(6569762.5000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(8025976., grad_fn=&lt;MseLossBackward0&gt;)
tensor(5783595., grad_fn=&lt;MseLossBackward0&gt;)
tensor(4533934.5000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1997666.1250, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2004032.8750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(25588.5957, grad_fn=&lt;MseLossBackward0&gt;)
tensor(379602.7812, grad_fn=&lt;MseLossBackward0&gt;)
tensor(8045948.5000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(3089504.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(5630250.5000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(854514.2500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1580122.6250, grad_fn=&lt;MseLossBackward0&gt;)
tensor(9193628., grad_fn=&lt;MseLossBackward0&gt;)
tensor(128968.6641, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1670929.8750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1254736.8750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2535173., grad_fn=&lt;MseLossBackward0&gt;)
tensor(528035.6875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(4599877., grad_fn=&lt;MseLossBackward0&gt;)
tensor(1754838.3750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2620946., grad_fn=&lt;MseLossBackward0&gt;)
tensor(1700487.3750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1380360., grad_fn=&lt;MseLossBackward0&gt;)
tensor(131735.6875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(394955.7812, grad_fn=&lt;MseLossBackward0&gt;)
tensor(5332.2085, grad_fn=&lt;MseLossBackward0&gt;)
tensor(6262877.5000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(576035.0625, grad_fn=&lt;MseLossBackward0&gt;)
tensor(3134015., grad_fn=&lt;MseLossBackward0&gt;)
tensor(3981889.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(31548.3848, grad_fn=&lt;MseLossBackward0&gt;)
tensor(43048.5508, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1267220.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2754742.5000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1623688.1250, grad_fn=&lt;MseLossBackward0&gt;)
tensor(799257.8125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2852575.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1129285., grad_fn=&lt;MseLossBackward0&gt;)
tensor(5696063., grad_fn=&lt;MseLossBackward0&gt;)
tensor(588753.5000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(85174.2031, grad_fn=&lt;MseLossBackward0&gt;)
tensor(179881.5938, grad_fn=&lt;MseLossBackward0&gt;)
tensor(553601.3750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1017881., grad_fn=&lt;MseLossBackward0&gt;)
tensor(336.8515, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2092113.6250, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1474040.2500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(689778.9375, grad_fn=&lt;MseLossBackward0&gt;)
tensor(845809.8125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(614982.9375, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1456556.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(22297.1387, grad_fn=&lt;MseLossBackward0&gt;)
tensor(299480.9688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(281979.6562, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1540737.8750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(571171.3750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(68729.7422, grad_fn=&lt;MseLossBackward0&gt;)
tensor(475251.3438, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1260493., grad_fn=&lt;MseLossBackward0&gt;)
tensor(1407893.5000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(677600.6875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1021236.5625, grad_fn=&lt;MseLossBackward0&gt;)
tensor(570050.0625, grad_fn=&lt;MseLossBackward0&gt;)
tensor(553846.3125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(9212.1562, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1395014.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(257966.7812, grad_fn=&lt;MseLossBackward0&gt;)
tensor(594758.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(423076.5625, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1312152.3750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(126852.4922, grad_fn=&lt;MseLossBackward0&gt;)
tensor(80669.0391, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1004843.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(25011.7012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(44540.3711, grad_fn=&lt;MseLossBackward0&gt;)
tensor(207787.2969, grad_fn=&lt;MseLossBackward0&gt;)
tensor(663612.3125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(87480.7734, grad_fn=&lt;MseLossBackward0&gt;)
tensor(162032.9844, grad_fn=&lt;MseLossBackward0&gt;)
tensor(297660.2812, grad_fn=&lt;MseLossBackward0&gt;)
tensor(39607.0234, grad_fn=&lt;MseLossBackward0&gt;)
tensor(642594.8125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(368919.8125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(668199.2500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(507437.0938, grad_fn=&lt;MseLossBackward0&gt;)
tensor(117289.5234, grad_fn=&lt;MseLossBackward0&gt;)
tensor(9352.4385, grad_fn=&lt;MseLossBackward0&gt;)
tensor(306672.5938, grad_fn=&lt;MseLossBackward0&gt;)
tensor(187027.5312, grad_fn=&lt;MseLossBackward0&gt;)
tensor(29711.7949, grad_fn=&lt;MseLossBackward0&gt;)
tensor(581607.3125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(78159.0156, grad_fn=&lt;MseLossBackward0&gt;)
tensor(33897.5195, grad_fn=&lt;MseLossBackward0&gt;)
tensor(245715.7812, grad_fn=&lt;MseLossBackward0&gt;)
tensor(27524.8828, grad_fn=&lt;MseLossBackward0&gt;)
tensor(69760.2109, grad_fn=&lt;MseLossBackward0&gt;)
tensor(294287.1875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(300696.4062, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2979.8379, grad_fn=&lt;MseLossBackward0&gt;)
tensor(31175.6953, grad_fn=&lt;MseLossBackward0&gt;)
tensor(181176.5938, grad_fn=&lt;MseLossBackward0&gt;)
tensor(36089.6094, grad_fn=&lt;MseLossBackward0&gt;)
tensor(12538.2041, grad_fn=&lt;MseLossBackward0&gt;)
tensor(274085.4688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(39457.9023, grad_fn=&lt;MseLossBackward0&gt;)
tensor(120143.1328, grad_fn=&lt;MseLossBackward0&gt;)
tensor(57.8357, grad_fn=&lt;MseLossBackward0&gt;)
tensor(205995.4219, grad_fn=&lt;MseLossBackward0&gt;)
tensor(4740.1343, grad_fn=&lt;MseLossBackward0&gt;)
tensor(69522.3438, grad_fn=&lt;MseLossBackward0&gt;)
tensor(6058.8130, grad_fn=&lt;MseLossBackward0&gt;)
tensor(182932.4688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1775.9557, grad_fn=&lt;MseLossBackward0&gt;)
tensor(88464.1250, grad_fn=&lt;MseLossBackward0&gt;)
tensor(216301.7500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(164637.8125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(55552.7422, grad_fn=&lt;MseLossBackward0&gt;)
tensor(142116.4844, grad_fn=&lt;MseLossBackward0&gt;)
tensor(7043.0449, grad_fn=&lt;MseLossBackward0&gt;)
tensor(63670.9609, grad_fn=&lt;MseLossBackward0&gt;)
tensor(140223.1875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(38258.0625, grad_fn=&lt;MseLossBackward0&gt;)
tensor(95772.7188, grad_fn=&lt;MseLossBackward0&gt;)
tensor(73925.8359, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2549.5103, grad_fn=&lt;MseLossBackward0&gt;)
tensor(117167.8203, grad_fn=&lt;MseLossBackward0&gt;)
tensor(15822.8887, grad_fn=&lt;MseLossBackward0&gt;)
tensor(70875.5391, grad_fn=&lt;MseLossBackward0&gt;)
tensor(618.2313, grad_fn=&lt;MseLossBackward0&gt;)
tensor(108391.4141, grad_fn=&lt;MseLossBackward0&gt;)
tensor(5892.9609, grad_fn=&lt;MseLossBackward0&gt;)
tensor(25092.8496, grad_fn=&lt;MseLossBackward0&gt;)
tensor(18408.9785, grad_fn=&lt;MseLossBackward0&gt;)
tensor(110383.8984, grad_fn=&lt;MseLossBackward0&gt;)
tensor(3473.5713, grad_fn=&lt;MseLossBackward0&gt;)
tensor(45406.4492, grad_fn=&lt;MseLossBackward0&gt;)
tensor(68950.8594, grad_fn=&lt;MseLossBackward0&gt;)
tensor(16553.3105, grad_fn=&lt;MseLossBackward0&gt;)
tensor(103790., grad_fn=&lt;MseLossBackward0&gt;)
tensor(1067.5791, grad_fn=&lt;MseLossBackward0&gt;)
tensor(22363.9766, grad_fn=&lt;MseLossBackward0&gt;)
tensor(82489.8438, grad_fn=&lt;MseLossBackward0&gt;)
tensor(12118.9141, grad_fn=&lt;MseLossBackward0&gt;)
tensor(10346.6045, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1892.2500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(6260.9976, grad_fn=&lt;MseLossBackward0&gt;)
tensor(76310.8281, grad_fn=&lt;MseLossBackward0&gt;)
tensor(24406.4336, grad_fn=&lt;MseLossBackward0&gt;)
tensor(41235.1719, grad_fn=&lt;MseLossBackward0&gt;)
tensor(50131.3867, grad_fn=&lt;MseLossBackward0&gt;)
tensor(13964.5918, grad_fn=&lt;MseLossBackward0&gt;)
tensor(20052.9395, grad_fn=&lt;MseLossBackward0&gt;)
tensor(12091.7295, grad_fn=&lt;MseLossBackward0&gt;)
tensor(44238.5352, grad_fn=&lt;MseLossBackward0&gt;)
tensor(8997.7451, grad_fn=&lt;MseLossBackward0&gt;)
tensor(16977.7852, grad_fn=&lt;MseLossBackward0&gt;)
tensor(36235.7617, grad_fn=&lt;MseLossBackward0&gt;)
tensor(39488.7539, grad_fn=&lt;MseLossBackward0&gt;)
tensor(3396.1350, grad_fn=&lt;MseLossBackward0&gt;)
tensor(6115.8052, grad_fn=&lt;MseLossBackward0&gt;)
tensor(43898.4336, grad_fn=&lt;MseLossBackward0&gt;)
tensor(7646.8535, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1718.7260, grad_fn=&lt;MseLossBackward0&gt;)
tensor(9952.3027, grad_fn=&lt;MseLossBackward0&gt;)
tensor(29442.5723, grad_fn=&lt;MseLossBackward0&gt;)
tensor(434.0549, grad_fn=&lt;MseLossBackward0&gt;)
tensor(8710.5039, grad_fn=&lt;MseLossBackward0&gt;)
tensor(19052.3555, grad_fn=&lt;MseLossBackward0&gt;)
tensor(6065.9604, grad_fn=&lt;MseLossBackward0&gt;)
tensor(3110.9487, grad_fn=&lt;MseLossBackward0&gt;)
tensor(109.2678, grad_fn=&lt;MseLossBackward0&gt;)
tensor(5956.2520, grad_fn=&lt;MseLossBackward0&gt;)
tensor(20417.4512, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1736.3010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1516.0909, grad_fn=&lt;MseLossBackward0&gt;)
tensor(7944.1362, grad_fn=&lt;MseLossBackward0&gt;)
tensor(23.6515, grad_fn=&lt;MseLossBackward0&gt;)
tensor(297.6636, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2779.6785, grad_fn=&lt;MseLossBackward0&gt;)
tensor(7844.5273, grad_fn=&lt;MseLossBackward0&gt;)
tensor(11828.2617, grad_fn=&lt;MseLossBackward0&gt;)
tensor(644.9814, grad_fn=&lt;MseLossBackward0&gt;)
tensor(3045.9836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2930.4670, grad_fn=&lt;MseLossBackward0&gt;)
tensor(3197.6594, grad_fn=&lt;MseLossBackward0&gt;)
tensor(13068.6875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(2035.1200, grad_fn=&lt;MseLossBackward0&gt;)
tensor(4551.7686, grad_fn=&lt;MseLossBackward0&gt;)
tensor(13338.1074, grad_fn=&lt;MseLossBackward0&gt;)
tensor(3780.8689, grad_fn=&lt;MseLossBackward0&gt;)
</pre>
</div>
</div>

</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
</p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[5892.3145],
        [6237.1528],
        [6581.9897],
        [6926.8257],
        [7271.6616],
        [7616.4976],
        [7961.3335],
        [8306.1768],
        [8651.0127],
        [8995.8486]], grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">actual</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
</p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[6000.0000],
        [6320.7002],
        [6641.4004],
        [6962.1006],
        [7282.8008],
        [7603.5010],
        [7924.2012],
        [8244.9014],
        [8565.6016],
        [8886.3018]])</pre>
</div>

</div>

</div>
</div>

    </details>
</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="nakulpyasi/Unified-AI"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Unified-AI/jupyter/2022/08/14/_NN_FROM_SCRATCH_PYTORCH.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Unified-AI/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Unified-AI/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Unified-AI/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Blogs about Deeplearning and ML</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/Unified-AI/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/Unified-AI/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
